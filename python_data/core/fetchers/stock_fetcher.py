# from vnstock import Quote
# from datetime import datetime
# from functools import lru_cache
# import time
# import traceback
# import pandas as pd

# _last_call = 0

# @lru_cache(maxsize=32)
# def fetch_stock(symbol: str, start: str, end: str):
#     """L·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ 10 nƒÉm g·∫ßn nh·∫•t cho 1 c·ªï phi·∫øu, KH√îNG L∆ØU FILE"""
#     global _last_call
#     now = time.time()

#     # Gi·ªõi h·∫°n t·∫ßn su·∫•t tr√°nh b·ªã ch·∫∑n
#     if now - _last_call < 2:
#         wait_time = 2 - (now - _last_call)
#         print(f"‚è∏Ô∏è Ch·ªù {wait_time:.2f}s ƒë·ªÉ tr√°nh b·ªã ch·∫∑n...")
#         time.sleep(wait_time)

#     _last_call = time.time()
#     print(f"üìà Fetching: {symbol} ({start} ‚Üí {end})")

#     try:
#         # Parse ng√†y th√†nh datetime
#         start_dt = pd.to_datetime(start)
#         end_dt = pd.to_datetime(end)

#         # t·∫°o instance Quote
#         quote = Quote(symbol=symbol.upper(), source="VCI")

#         # Truy·ªÅn v√†o ƒë√∫ng format string
#         df = quote.history(
#             start=start_dt.strftime("%Y-%m-%d"),
#             end=end_dt.strftime("%Y-%m-%d"),
#             interval="1D"
#         )

#         if df is None or df.empty:
#             print(f"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu cho m√£ {symbol}")
#             return []

#         df = df.copy()

#         data = []
#         for _, row in df.iterrows():
#             try:
#                 # if hasattr(row["time"], "timestamp"):
#                 #     ts = int(row["time"].to_pydatetime().timestamp())
#                 # else:
#                 #     ts = int(datetime.strptime(str(row["time"]), "%Y-%m-%d").timestamp())
#                 if hasattr(row["time"], "strftime"):
#                     ts = row["time"].strftime("%Y-%m-%d")
#                 else:
#                     try:
#                         ts = datetime.strptime(str(row["time"]), "%Y-%m-%d").strftime("%Y-%m-%d")
#                     except Exception:
#                         ts = str(row["time"])[:10]

#                 data.append({
#                     "time": ts,
#                     "open": float(row["open"]),
#                     "high": float(row["high"]),
#                     "low": float(row["low"]),
#                     "close": float(row["close"]),
#                     "volume": int(row.get("volume", 0)),
#                 })
#             except Exception as e:
#                 print(f"‚ö†Ô∏è L·ªói d√≤ng d·ªØ li·ªáu: {e}")
#                 continue

#         print(f"L·∫•y {len(data)} phi√™n giao d·ªãch cho {symbol}")
#         return data

#     except Exception as e:
#         print(f"‚ùå L·ªói fetch {symbol}: {e}")
#         traceback.print_exc()
#         return []








# from vnstock import Quote
# from datetime import datetime
# from functools import lru_cache
# import os, time, json, traceback, pandas as pd
# from core.utils import save_json  # d√πng h√†m chung

# _last_call = 0
# BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# CACHE_DIR = os.path.join(BASE_DIR, "../../data/stocks")

# def load_json(filename):
#     os.makedirs(CACHE_DIR, exist_ok=True)
#     path = os.path.join(CACHE_DIR, filename)
#     if os.path.exists(path):
#         with open(path, "r", encoding="utf-8") as f:
#             return json.load(f)
#     return None

# def _fetch_from_api(symbol: str, start: str, end: str):
#     global _last_call
#     now = time.time()
#     if now - _last_call < 2:
#         wait_time = 2 - (now - _last_call)
#         print(f"‚è∏Ô∏è Ch·ªù {wait_time:.2f}s ƒë·ªÉ tr√°nh b·ªã ch·∫∑n...")
#         time.sleep(wait_time)
#     _last_call = time.time()

#     print(f"üìà Fetching t·ª´ vnstock: {symbol} ({start} ‚Üí {end})")
#     start_dt = pd.to_datetime(start)
#     end_dt = pd.to_datetime(end)
#     quote = Quote(symbol=symbol, source="VCI")

#     df = quote.history(start=start_dt.strftime("%Y-%m-%d"), end=end_dt.strftime("%Y-%m-%d"), interval="1D")

#     if df is None or df.empty:
#         print(f"‚ö†Ô∏è API tr·∫£ r·ªóng cho {symbol}")
#         return []

#     data = []
#     for _, row in df.iterrows():
#         try:
#             ts = row["time"].strftime("%Y-%m-%d") if hasattr(row["time"], "strftime") else str(row["time"])[:10]
#             data.append({
#                 "time": ts,
#                 "open": float(row["open"]),
#                 "high": float(row["high"]),
#                 "low": float(row["low"]),
#                 "close": float(row["close"]),
#                 "volume": int(row.get("volume", 0)),
#             })
#         except Exception as e:
#             print(f"‚ö†Ô∏è L·ªói d√≤ng d·ªØ li·ªáu: {e}")
#     return data

# @lru_cache(maxsize=32)
# def fetch_stock(symbol: str, start: str, end: str):
#     symbol = symbol.upper()
#     cache_file = f"{symbol}.json"
#     today = datetime.today().strftime("%Y-%m-%d")
#     current_hour = datetime.now().hour

#     cached_data = load_json(cache_file)
#     last_cached_date = None
#     if cached_data:
#         try:
#             last_cached_date = cached_data[-1]["time"]
#             print(f"üì¶ Cache {symbol}: ƒë·∫øn {last_cached_date}")
#         except Exception:
#             print(f"‚ö†Ô∏è Cache {symbol} l·ªói ƒë·ªãnh d·∫°ng, b·ªè qua cache.")
           















# from vnstock import Quote
# from datetime import datetime
# from functools import lru_cache
# import os, time, json, traceback, pandas as pd

# _last_call = 0

# # L·∫•y ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi t·ªõi th∆∞ m·ª•c data/stocks/
# BASE_DIR = os.path.dirname(os.path.abspath(__file__))               # core/fetchers/
# CACHE_DIR = os.path.abspath(os.path.join(BASE_DIR, "../../data/stocks"))  # data/stocks

# def save_json(filename, data):
#     """L∆∞u JSON c√≥ format ƒë·∫πp v√†o data/stocks"""
#     os.makedirs(CACHE_DIR, exist_ok=True)
#     path = os.path.join(CACHE_DIR, filename)
#     with open(path, "w", encoding="utf-8") as f:
#         json.dump(data, f, ensure_ascii=False, indent=2)
#     print(f"üíæ Saved {filename} ‚Üí {path}")

# def load_json(filename):
#     """ƒê·ªçc JSON n·∫øu t·ªìn t·∫°i"""
#     path = os.path.join(CACHE_DIR, filename)
#     if os.path.exists(path):
#         with open(path, "r", encoding="utf-8") as f:
#             return json.load(f)
#     return None


# def _fetch_from_api(symbol: str, start: str, end: str):
#     """H√†m g·ªçi API vnstock th·∫≠t s·ª±"""
#     global _last_call
#     now = time.time()

#     # Gi·ªõi h·∫°n t·∫ßn su·∫•t
#     if now - _last_call < 2:
#         wait_time = 2 - (now - _last_call)
#         print(f"‚è∏Ô∏è Ch·ªù {wait_time:.2f}s ƒë·ªÉ tr√°nh b·ªã ch·∫∑n...")
#         time.sleep(wait_time)

#     _last_call = time.time()

#     print(f"üìà Fetching t·ª´ vnstock: {symbol} ({start} ‚Üí {end})")
#     start_dt = pd.to_datetime(start)
#     end_dt = pd.to_datetime(end)
#     quote = Quote(symbol=symbol, source="VCI")
#     print(f"üîó API URL: c√†i m√£ m·ªõi",symbol)
#     df = quote.history(
#         start=start_dt.strftime("%Y-%m-%d"),
#         end=end_dt.strftime("%Y-%m-%d"),
#         interval="1D",
#     )

#     if df is None or df.empty:
#         print(f"‚ö†Ô∏è API tr·∫£ r·ªóng cho {symbol}")
#         return []

#     data = []
#     for _, row in df.iterrows():
#         try:
#             ts = (
#                 row["time"].strftime("%Y-%m-%d")
#                 if hasattr(row["time"], "strftime")
#                 else str(row["time"])[:10]
#             )
#             data.append(
#                 {
#                     "time": ts,
#                     "open": float(row["open"]),
#                     "high": float(row["high"]),
#                     "low": float(row["low"]),
#                     "close": float(row["close"]),
#                     "volume": int(row.get("volume", 0)),
#                 }
#             )
#         except Exception as e:
#             print(f"‚ö†Ô∏è L·ªói d√≤ng d·ªØ li·ªáu: {e}")
#             continue

#     print(f"L·∫•y {len(data)} phi√™n giao d·ªãch cho {symbol}")
#     return data


# @lru_cache(maxsize=32)
# def fetch_stock(symbol: str, start: str, end: str):
#     """
#     L·∫•y d·ªØ li·ªáu c·ªï phi·∫øu (10 nƒÉm g·∫ßn nh·∫•t)
#     Cache local: data/stocks/<symbol>.json
#     Ch·ªâ g·ªçi l·∫°i API khi:
#        - Sang ng√†y m·ªõi & sau 17h
#        - Cache r·ªóng ho·∫∑c l·ªói
#        - API tr·∫£ l·ªói ho·∫∑c []
#     """
#     symbol = symbol.upper()
#     cache_file = f"{symbol}.json"
#     today = datetime.today().strftime("%Y-%m-%d")
#     current_hour = datetime.now().hour

#     # Th·ª≠ ƒë·ªçc cache tr∆∞·ªõc
#     cached_data = load_json(cache_file)
#     last_cached_date = None
#     if cached_data:
#         try:
#             last_cached_date = cached_data[-1]["time"]
#             print(f"üì¶ Cache {symbol}: ƒë·∫øn {last_cached_date}")
#         except Exception:
#             print(f"‚ö†Ô∏è Cache {symbol} l·ªói ƒë·ªãnh d·∫°ng, b·ªè qua cache.")
#             cached_data = None

#     # Quy·∫øt ƒë·ªãnh c√≥ c·∫ßn c·∫≠p nh·∫≠t kh√¥ng
#     need_update = False
#     if not cached_data:
#         print(f"Kh√¥ng c√≥ cache cho {symbol}, c·∫ßn fetch m·ªõi.")
#         need_update = True
#     elif today > last_cached_date and current_hour >= 17:
#         print(f"üåá Sang ng√†y m·ªõi ({today}), sau 17h ‚Üí c·∫≠p nh·∫≠t {symbol}.")
#         need_update = True

#     # N·∫øu c·∫ßn c·∫≠p nh·∫≠t ‚Üí fetch API
#     if need_update:
#         data = _fetch_from_api(symbol, start, end)
#         if data:  
#             save_json(cache_file, data)
#             return data
#         else:
#             print(f"‚ö†Ô∏è API l·ªói ho·∫∑c r·ªóng, fallback d√πng cache c≈© (n·∫øu c√≥).")
#             return cached_data or []

#     # N·∫øu kh√¥ng c·∫ßn update ‚Üí d√πng cache
#     print(f"D√πng cache c≈© cho {symbol}")
#     return cached_data



















from vnstock import Quote
from datetime import datetime, timedelta
from functools import lru_cache
import os, time, json, traceback, pandas as pd

_last_call = 0

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CACHE_DIR = os.path.abspath(os.path.join(BASE_DIR, "../../data/stocks"))

def save_json(filename, data):
    """L∆∞u JSON c√≥ format ƒë·∫πp v√†o data/stocks"""
    os.makedirs(CACHE_DIR, exist_ok=True)
    path = os.path.join(CACHE_DIR, filename)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"üíæ Saved {filename} ‚Üí {path}")

def load_json(filename):
    """ƒê·ªçc JSON n·∫øu t·ªìn t·∫°i"""
    path = os.path.join(CACHE_DIR, filename)
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return None


def _fetch_from_api(symbol: str, start: str, end: str):
    """H√†m g·ªçi API vnstock th·∫≠t s·ª±"""
    global _last_call
    now = time.time()

    if now - _last_call < 2:
        wait_time = 2 - (now - _last_call)
        print(f"‚è∏Ô∏è Ch·ªù {wait_time:.2f}s ƒë·ªÉ tr√°nh b·ªã ch·∫∑n...")
        time.sleep(wait_time)

    _last_call = time.time()

    print(f"üìà Fetching t·ª´ vnstock: {symbol} ({start} ‚Üí {end})")
    start_dt = pd.to_datetime(start)
    end_dt = pd.to_datetime(end)
    quote = Quote(symbol=symbol, source="VCI")
    print(f"üîó API URL: c√†i m√£ m·ªõi",symbol)
    df = quote.history(
        start=start_dt.strftime("%Y-%m-%d"),
        end=end_dt.strftime("%Y-%m-%d"),
        interval="1D",
    )

    if df is None or df.empty:
        print(f"API tr·∫£ r·ªóng cho {symbol}")
        return []

    data = []
    for _, row in df.iterrows():
        try:
            ts = (
                row["time"].strftime("%Y-%m-%d")
                if hasattr(row["time"], "strftime")
                else str(row["time"])[:10]
            )
            data.append(
                {
                    "time": ts,
                    "open": float(row["open"]),
                    "high": float(row["high"]),
                    "low": float(row["low"]),
                    "close": float(row["close"]),
                    "volume": int(row.get("volume", 0)),
                }
            )
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói d√≤ng d·ªØ li·ªáu: {e}")
            continue

    return data


def get_last_trading_day():
    today = datetime.today()
    wd = today.weekday()

    if wd == 5:
        return (today - timedelta(days=1)).strftime("%Y-%m-%d")
    if wd == 6:
        return (today - timedelta(days=2)).strftime("%Y-%m-%d")
    return today.strftime("%Y-%m-%d")


@lru_cache(maxsize=32)
def fetch_stock(symbol: str, start: str, end: str):
    symbol = symbol.upper()
    cache_file = f"{symbol}.json"
    today = datetime.today().strftime("%Y-%m-%d")
    current_hour = datetime.now().hour

    cached_data = load_json(cache_file)
    last_cached_date = None
    if cached_data:
        try:
            last_cached_date = cached_data[-1]["time"]
            print(f"üì¶ Cache {symbol}: ƒë·∫øn {last_cached_date}")
        except Exception:
            print(f"‚ö†Ô∏è Cache {symbol} l·ªói ƒë·ªãnh d·∫°ng, b·ªè qua cache.")
            cached_data = None

    need_update = False
    if not cached_data:
        print(f"üÜï Kh√¥ng c√≥ cache cho {symbol}, c·∫ßn fetch m·ªõi.")
        need_update = True
    elif today > last_cached_date and current_hour >= 17:
        print(f"üåá Sang ng√†y m·ªõi ({today}), sau 17h ‚Üí c·∫≠p nh·∫≠t {symbol}.")
        need_update = True

    weekday = datetime.today().weekday()  # 5=Sat, 6=Sun
    last_trading_day = get_last_trading_day()

    if weekday >= 5:
        if last_cached_date and last_cached_date >= last_trading_day:
            print(f"üìÜ Cu·ªëi tu·∫ßn v√† cache ƒë√£ ƒë·ªß ƒë·∫øn {last_trading_day} ‚Üí KH√îNG c·∫≠p nh·∫≠t.")
            need_update = False
        else:
            print(f"üìÜ Cu·ªëi tu·∫ßn nh∆∞ng cache thi·∫øu ‚Üí v·∫´n c·∫≠p nh·∫≠t 1 l·∫ßn.")
            need_update = True

    if need_update:
        data = _fetch_from_api(symbol, start, end)
        if data:
            save_json(cache_file, data)
            return data
        else:
            print(f"‚ö†Ô∏è API l·ªói ho·∫∑c r·ªóng, fallback d√πng cache c≈© (n·∫øu c√≥).")
            return cached_data or []

    return cached_data




























