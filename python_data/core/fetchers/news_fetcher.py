from vnstock import Company
from datetime import datetime
from functools import lru_cache
import os, time, json, traceback, pandas as pd, re, unicodedata

_last_call = 0

# âœ… ÄÆ°á»ng dáº«n thÆ° má»¥c cache
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CACHE_DIR = os.path.abspath(os.path.join(BASE_DIR, "../../data/news"))
os.makedirs(CACHE_DIR, exist_ok=True)

# =====================================================
# ğŸ§  Utils
# =====================================================
def save_json(filename, data):
    """LÆ°u file JSON format Ä‘áº¹p"""
    path = os.path.join(CACHE_DIR, filename)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ Saved {filename} â†’ {path}")


def load_json(filename):
    """Äá»c cache náº¿u tá»“n táº¡i"""
    path = os.path.join(CACHE_DIR, filename)
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return None


def _safe_date(x):
    """Convert ngÃ y vá» dáº¡ng chuáº©n YYYY-MM-DD HH:MM:SS"""
    if pd.isna(x) or x in ["", None]:
        return None
    try:
        if isinstance(x, (int, float)):
            if x > 1e12:
                x = x / 1000
            dt = datetime.fromtimestamp(x)
            if dt.year < 2000:
                return None
            return dt.strftime("%Y-%m-%d %H:%M:%S")

        if hasattr(x, "strftime"):
            return x.strftime("%Y-%m-%d %H:%M:%S")

        s = str(x).strip()
        if s.isdigit():
            return _safe_date(float(s))
        dt = pd.to_datetime(s, errors="coerce")
        if pd.isna(dt) or dt.year < 2000:
            return None
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return None


def slugify(text: str):
    """Táº¡o slug sáº¡ch tá»« title â€” bá» dáº¥u, kÃ½ tá»± Ä‘áº·c biá»‡t"""
    if not text:
        return ""
    text = unicodedata.normalize("NFD", text)
    text = text.encode("ascii", "ignore").decode("utf-8")
    text = re.sub(r"[^a-zA-Z0-9]+", "-", text)
    return text.strip("-").lower()


# =====================================================
# ğŸ“° Fetch logic
# =====================================================
def _fetch_from_api(symbol: str, limit: int = 300):
    """Gá»i vnstock.Company.news()"""
    global _last_call
    now = time.time()
    if now - _last_call < 2:
        time.sleep(2 - (now - _last_call))
    _last_call = time.time()

    try:
        print(f"ğŸ“° Fetching news for {symbol}")
        company = Company(symbol=symbol, source="VCI")
        df = company.news()

        if df is None or df.empty:
            print(f"âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u news cho {symbol}")
            return {}

        # âœ… Æ¯u tiÃªn 'public_date', fallback 'publish_time'
        if "public_date" in df.columns:
            df["public_date"] = df["public_date"].apply(_safe_date)
            df = df.sort_values("public_date", ascending=False)
        elif "publish_time" in df.columns:
            df["public_date"] = df["publish_time"].apply(_safe_date)
            df = df.sort_values("public_date", ascending=False)
        else:
            df["public_date"] = None

        df = df.head(limit)

        # âœ… Convert tá»«ng dÃ²ng
        records = []
        for _, row in df.iterrows():
            title = str(row.get("news_title", "")).strip()
            slug = slugify(title) or f"news-{row.get('news_id', '')}"

            records.append({
                "news_id": str(row.get("news_id", "")),
                "news_title": title,
                "news_sub_title": str(row.get("news_sub_title", "")),
                "news_short_content": str(row.get("news_short_content", "")),
                "news_full_content": str(row.get("news_full_content", "")),
                "news_image_url": str(row.get("news_image_url", "")),
                "news_source_link": str(row.get("news_source_link", "")),
                "public_date": _safe_date(row.get("public_date")),
                "slug": slug,
            })

        data = {
            "symbol": symbol.upper(),
            "count": len(records),
            "data": records,
            "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }

        print(f"âœ… Láº¥y {len(records)} bÃ i cho {symbol}")
        return data

    except Exception as e:
        print(f"âŒ Lá»—i fetch_news({symbol}): {e}")
        traceback.print_exc()
        return {}


# =====================================================
# âš¡ Public fetcher (cÃ³ cache)
# =====================================================
@lru_cache(maxsize=32)
def fetch_news(symbol: str):
    """
    Láº¥y tin tá»©c doanh nghiá»‡p:
    âœ… LÆ°u local: data/news/<symbol>_news.json
    âœ… Cáº­p nháº­t láº¡i khi qua ngÃ y má»›i & sau 17h
    âœ… Giá»¯ Ä‘Ãºng ngÃ y + giá» public_date
    """
    symbol = symbol.upper()
    cache_file = f"{symbol}_news.json"
    today = datetime.today().strftime("%Y-%m-%d")
    current_hour = datetime.now().hour

    cached = load_json(cache_file)
    last_update = cached.get("updated_at") if cached else None

    need_update = False
    if not cached:
        print(f"ğŸ†• KhÃ´ng cÃ³ cache cho {symbol}")
        need_update = True
    elif today > str(last_update)[:10] and current_hour >= 17:
        print(f"ğŸŒ‡ Sang ngÃ y má»›i ({today}) â†’ cáº­p nháº­t news {symbol}")
        need_update = True

    if need_update:
        data = _fetch_from_api(symbol)
        if data and data.get("data"):
            save_json(cache_file, data)
            return data
        print("âš ï¸ API lá»—i hoáº·c rá»—ng, fallback cache cÅ©")
        return cached or {}

    print(f"âœ… DÃ¹ng cache cÅ© cho {symbol}")
    return cached
